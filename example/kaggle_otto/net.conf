# example configure file for mnist
# training iterator
data = train
iter = csv
    filename = "./tr.csv"
    has_header = 0
    label_width = 1
    input_shape = 1,1,93
#iter = membuffer
iter = end
# evaluation iterator
eval = test
iter = csv
    filename = "./va.csv"
    has_header = 0
    label_width = 1
    input_shape = 1,1,93
#iter = membuffer
iter = end


netconfig=start
layer[+1] = conv
  kernel_width = 16
  kernel_height = 1
  nchannel = 128
layer[+1] = rrelu
layer[+0] = dropout
  threshold = 0.65
layer[+1] = conv
  kernel_width = 16
  kernel_height = 1
  nchannel = 128
layer[+1] = rrelu
layer[+0] = dropout
  threshold = 0.65
layer[+1] = flatten
layer[+1] = fullc
  nhidden = 1024
layer[+1] = rrelu
layer[+0] = dropout
  threshold = 0.65
layer[+1] = fullc
  nhidden = 512
layer[+1] = rrelu
layer[+0] = dropout
  threshold = 0.5
layer[+1] = fullc
  nhidden = 9
  init_sigma = 0.01
layer[+0] = softmax
netconfig=end

# input shape not including batch
input_shape = 1,1,93
batch_size = 100

## global parameters
dev = gpu
save_model = 1
max_round = 100
num_round = 100
random_type = xavier
## learning parameters

momentum = 0.9
wmat:lr  = 0.01
wmat:wd  = 0.0005

bias:wd  = 0.000
bias:lr  = 0.02


lr:schedule = factor
lr:factor = 0.25
lr:step = 15000
# evaluation metric
metric[label] = error
metric[label] = logloss
# end of config
